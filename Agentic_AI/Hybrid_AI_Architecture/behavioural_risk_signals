hese four numbers are behavioural risk signals (typology indicators) extracted from transaction activity by the LLM.
They are not predictions of guilt and not final risk scores.
They are features — measurable evidence patterns the classifier uses to estimate laundering probability.

Think of them as the AML equivalent of medical biomarkers.

transactions → behaviour indicators → probability of laundering → action


Below is exactly what each one means operationally and how it is created.

1) structuring_score: 0.82
What it detects

Structuring / smurfing (placement stage of laundering)

This is when a person intentionally breaks a large amount of cash into many small deposits to avoid reporting thresholds.

Typical pattern:

$9,400
$9,700
$9,200
$9,800
(at different branches/ATMs/days)

How the signal is created

The system looks for statistical and behavioural patterns such as:

repeated deposits just below regulatory reporting limits

multiple locations

multiple days

round-number clustering

same-day aggregation after deposits

Example engineered metrics:

\text{structuring\_index} = \frac{\text{# deposits near threshold}}{\text{total deposits}} \times location\ dispersion \times time\ regularity

The LLM reads the activity summary and recognises:

“These transactions look intentionally split.”

What 0.82 means

On a 0–1 scale:

Score	Interpretation
0.0–0.3	normal cash behaviour
0.3–0.6	unusual
0.6–1.0	deliberate avoidance pattern

0.82 = strong placement behaviour.

2) mule_account_probability: 0.71
What it detects

Money mule account usage

A mule account is an intermediary account used to receive illicit funds and quickly pass them on.

Typical characteristics:

receives funds from many unrelated senders

forwards funds quickly

keeps low balance

new beneficiary relationships

young account age

Signal creation

The LLM is interpreting network behaviour summarized from transaction features:

Important inputs:

counterparty diversity

incoming vs outgoing timing gap

account age

balance retention ratio

Example formula behind the scenes:

mule_features={high incoming diversity
short holding time
rapid outgoing transfers
mule_features=
⎩
⎨
⎧
	​

high incoming diversity
short holding time
rapid outgoing transfers
	​


LLM reads:

“Funds enter and leave rapidly without economic purpose.”

Meaning of 0.71

High probability the account is acting as a pass-through node, not a genuine personal or business account.

3) circular_transactions: 0.65
What it detects

Layering / circular money movement

This is when money moves through multiple accounts and eventually returns to a related account to disguise origin.

Example:

A → B → C → D → A


This is classic laundering layering.

How it is generated

The system builds a transaction graph:

accounts = nodes

transfers = edges

Then measures:

closed loops

short cycle paths

repeated counterparties

same-amount transfers

Graph metric example:

circularity=closed transfer loopstotal transfers
circularity=
total transfers
closed transfer loops
	​


The LLM reads a graph summary and recognises a laundering topology.

What 0.65 means

Moderate–strong layering evidence.

4) velocity_anomaly: 0.44
What it detects

Speed of money movement

Legitimate accounts usually hold funds for a purpose.
Laundering accounts move money quickly to reduce traceability.

Key behaviour:

deposit → transfer out within minutes/hours

Signal creation

Calculated using time-based features:

velocity=transactions per hour×fund turnover ratecustomer baseline
velocity=
customer baseline
transactions per hour×fund turnover rate
	​


The LLM interprets a summary like:

“Funds are moved rapidly after arrival.”

Meaning of 0.44

Noticeable but not extreme.
It supports suspicion but alone is not decisive.

Why these signals matter

Each signal corresponds to a stage of the laundering lifecycle:

Signal	Laundering stage
structuring	placement
mule usage	movement
circular transactions	layering
velocity anomaly	concealment acceleration

So your system is no longer detecting a transaction.

It is detecting a coherent laundering process.

That is exactly why false positives drop — innocent customers rarely produce a full behavioural chain across stages.

Important: These are not the final decision

The classifier combines them:

P(laundering)=f(structuring, mule, circularity, velocity, financial features)
P(laundering)=f(structuring, mule, circularity, velocity, financial features)

Example:

A business might deposit cash (high structuring)

but not show mule or circular behaviour

→ model outputs “unclear” or “decline”, not escalate.

Why the LLM is used

Traditional ML struggles because:

transactions alone = weak signal

The LLM converts complex behavioural summaries into human-level typology recognition, then ML converts that into a calibrated probability.

You are effectively teaching the model how investigators think.
