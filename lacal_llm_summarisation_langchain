To perform text summarization with a local LLM using LangChain, youâ€™ll need:

    A local LLM (e.g., via Ollama, GPT4All, or llama-cpp).

    LangChain to structure the prompt and summarization pipeline.

âœ… Example: Summarizing Text with Ollama + LangChain

Let's walk through a working Python example using the mistral model via Ollama:
ðŸ”§ 1. Install Dependencies

pip install langchain langchain-community

Make sure Ollama is installed and a model like mistral is running:

ollama pull mistral
ollama run mistral

ðŸ§  2. Python Code for Summarization

from langchain_community.llms import Ollama
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# Load local model (Ollama must be running)
llm = Ollama(model="mistral")

# Create a prompt template for summarisation
prompt = PromptTemplate.from_template("""
Summarize the following text in 3-5 bullet points:

{text}
""")

# Create a LangChain LLM chain
summarization_chain = LLMChain(llm=llm, prompt=prompt)

# Your input text
long_text = """
Artificial intelligence is transforming various industries. In healthcare, it's being used to assist in diagnosis,
predict patient outcomes, and personalize treatment. In finance, AI powers fraud detection, algorithmic trading,
and customer service automation. Meanwhile, in education, it helps personalize learning experiences and automate grading.
However, these advancements also raise concerns about bias, data privacy, and job displacement.
"""

# Run the summarization
summary = summarization_chain.run(long_text)
print(summary)

ðŸ“¤ Output (Example)

- AI is revolutionizing healthcare, finance, and education.
- In healthcare, it aids diagnosis and personalizes treatment.
- In finance, it's used for fraud detection and trading.
- In education, it enhances learning and automates grading.
- Concerns include bias, privacy, and job loss.

ðŸ§° Other Local Options for Summarization

You can do the same thing with:

    GPT4All: Use from langchain_community.llms import GPT4All

    LLaMA.cpp: Use llama-cpp-python with LangChain

    HuggingFace models: Load summarization-specific models (like bart-large-cnn) and wrap them with LangChain
